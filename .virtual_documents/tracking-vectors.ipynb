from PIL import Image
import os

from transformers import CLIPProcessor, CLIPModel


from mots_tools.mots_common import io


model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")


DATA_DIR = '/data/kitti-mots'


objects = io.load_images_for_folder(os.path.join(DATA_DIR, 'instances/0000'))


len(objects)


objects[0]


objects[0][0]


objects[0][0].mask


objects[0][0].class_id


objects[0][0].track_id



