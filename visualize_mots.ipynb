{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fafdda-9b10-4e2a-871f-e36a153ed85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pycocotools.mask as rletools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "from mots_tools.mots_common.io import load_sequences, load_seqmap\n",
    "from functools import partial\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151f895f-e9ec-4916-9ffd-6da3aec9a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py\n",
    "def generate_colors():\n",
    "  \"\"\"\n",
    "  Generate random colors.\n",
    "  To get visually distinct colors, generate them in HSV space then\n",
    "  convert to RGB.\n",
    "  \"\"\"\n",
    "  N = 30\n",
    "  brightness = 0.7\n",
    "  hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "  colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "  perm = [15, 13, 25, 12, 19, 8, 22, 24, 29, 17, 28, 20, 2, 27, 11, 26, 21, 4, 3, 18, 9, 5, 14, 1, 16, 0, 23, 7, 6, 10]\n",
    "  colors = [colors[idx] for idx in perm]\n",
    "  return colors\n",
    "\n",
    "\n",
    "# from https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/visualize.py\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "  \"\"\"Apply the given mask to the image.\n",
    "  \"\"\"\n",
    "  for c in range(3):\n",
    "    image[:, :, c] = np.where(mask == 1,\n",
    "                              image[:, :, c] * (1 - alpha) + alpha * color[c],\n",
    "                              image[:, :, c])\n",
    "  return image\n",
    "\n",
    "\n",
    "def process_sequence(seq_id, tracks_folder, img_folder, output_folder, max_frames, draw_boxes=False,\n",
    "                     create_video=True):\n",
    "  print(\"Processing sequence\", seq_id)\n",
    "  os.makedirs(output_folder + \"/\" + seq_id, exist_ok=True)\n",
    "  tracks = load_sequences(tracks_folder, [seq_id])[seq_id]\n",
    "  max_frames_seq = max_frames[seq_id]\n",
    "  visualize_sequences(seq_id, tracks, max_frames_seq, img_folder, output_folder, draw_boxes, create_video)\n",
    "\n",
    "\n",
    "def visualize_sequences(seq_id, tracks, max_frames_seq, img_folder, output_folder, draw_boxes=False, create_video=True):\n",
    "  colors = generate_colors()\n",
    "  dpi = 100.0\n",
    "  frames_with_annotations = [frame for frame in tracks.keys() if len(tracks[frame]) > 0]\n",
    "  img_sizes = next(iter(tracks[frames_with_annotations[0]])).mask[\"size\"]\n",
    "  for t in range(max_frames_seq + 1):\n",
    "    print(\"Processing frame\", t)\n",
    "    filename_t = img_folder + \"/\" + seq_id + \"/%06d\" % t\n",
    "    if os.path.exists(filename_t + \".png\"):\n",
    "      filename_t = filename_t + \".png\"\n",
    "    elif os.path.exists(filename_t + \".jpg\"):\n",
    "      filename_t = filename_t + \".jpg\"\n",
    "    else:\n",
    "      print(\"Image file not found for \" + filename_t + \".png/.jpg, continuing...\")\n",
    "      continue\n",
    "    img = np.array(Image.open(filename_t), dtype=\"float32\") / 255\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(img_sizes[1] / dpi, img_sizes[0] / dpi, forward=True)\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "    ax = fig.subplots()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if t in tracks:\n",
    "      for obj in tracks[t]:\n",
    "        color = colors[obj.track_id % len(colors)]\n",
    "        if obj.class_id == 1:\n",
    "          category_name = \"Car\"\n",
    "        elif obj.class_id == 2:\n",
    "          category_name = \"Pedestrian\"\n",
    "        else:\n",
    "          category_name = \"Ignore\"\n",
    "          color = (0.7, 0.7, 0.7)\n",
    "        if obj.class_id == 1 or obj.class_id == 2:  # Don't show boxes or ids for ignore regions\n",
    "          x, y, w, h = rletools.toBbox(obj.mask)\n",
    "          if draw_boxes:\n",
    "            import matplotlib.patches as patches\n",
    "            rect = patches.Rectangle((x, y), w, h, linewidth=1,\n",
    "                                     edgecolor=color, facecolor='none', alpha=1.0)\n",
    "            ax.add_patch(rect)\n",
    "          category_name += \":\" + str(obj.track_id)\n",
    "          ax.annotate(category_name, (x + 0.5 * w, y + 0.5 * h), color=color, weight='bold',\n",
    "                      fontsize=7, ha='center', va='center', alpha=1.0)\n",
    "        binary_mask = rletools.decode(obj.mask)\n",
    "        apply_mask(img, binary_mask, color)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    fig.savefig(output_folder + \"/\" + seq_id + \"/%06d\" % t + \".jpg\")\n",
    "    plt.close(fig)\n",
    "  if create_video:\n",
    "    os.chdir(output_folder + \"/\" + seq_id)\n",
    "    call([\"ffmpeg\", \"-framerate\", \"10\", \"-y\", \"-i\", \"%06d.jpg\", \"-c:v\", \"libx264\", \"-profile:v\", \"high\", \"-crf\", \"20\",\n",
    "          \"-pix_fmt\", \"yuv420p\", \"-vf\", \"pad=\\'width=ceil(iw/2)*2:height=ceil(ih/2)*2\\'\", \"output.mp4\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195b034a-b3da-435d-bb4c-b286ca794c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence_2(seq_id, tracks_folder, img_folder, output_folder, max_frames, draw_boxes=False,\n",
    "                     create_video=True):\n",
    "    print(\"Processing sequence\", seq_id)\n",
    "    os.makedirs(output_folder + \"/\" + seq_id, exist_ok=True)\n",
    "    tracks = load_sequences(tracks_folder, [seq_id])[seq_id]\n",
    "    max_frames_seq = max_frames[seq_id]\n",
    "    visualize_sequences_2(seq_id, tracks, max_frames_seq, img_folder, output_folder, draw_boxes, create_video)\n",
    "\n",
    "\n",
    "def visualize_sequences_2(seq_id, tracks, max_frames_seq, img_folder, output_folder, draw_boxes=False, create_video=True):\n",
    "    if not os.path.exists(os.path.join(output_folder, 'sequences', seq_id)):\n",
    "        os.makedirs(os.path.join(output_folder, 'sequences', seq_id))\n",
    "    colors = generate_colors()\n",
    "    for t in range(max_frames_seq + 1):\n",
    "        # print(\"Processing frame\", t)\n",
    "        filename_t = img_folder + \"/\" + seq_id + \"/%06d\" % t\n",
    "        if os.path.exists(filename_t + \".png\"):\n",
    "            filename_t = filename_t + \".png\"\n",
    "        elif os.path.exists(filename_t + \".jpg\"):\n",
    "            filename_t = filename_t + \".jpg\"\n",
    "        else:\n",
    "            print(\"Image file not found for \" + filename_t + \".png/.jpg, continuing...\")\n",
    "            continue\n",
    "        img = np.array(Image.open(filename_t), dtype=\"float32\") / 255\n",
    "        # fig = plt.figure()\n",
    "        # fig.set_size_inches(img_sizes[1] / dpi, img_sizes[0] / dpi, forward=True)\n",
    "        # fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "        # ax = fig.subplots()\n",
    "        # ax.set_axis_off()\n",
    "\n",
    "        if t in tracks:\n",
    "            for obj in tracks[t]:\n",
    "                if not os.path.exists(os.path.join(output_folder, 'sequences', seq_id, str(obj.track_id))):\n",
    "                    os.makedirs(os.path.join(output_folder, 'sequences', seq_id, str(obj.track_id)))\n",
    "                color = colors[obj.track_id % len(colors)]\n",
    "                if obj.class_id == 1:\n",
    "                    category_name = \"Car\"\n",
    "                elif obj.class_id == 2:\n",
    "                    category_name = \"Pedestrian\"\n",
    "                else:\n",
    "                    category_name = \"Ignore\"\n",
    "                    color = (0.7, 0.7, 0.7)\n",
    "                if obj.class_id == 1 or obj.class_id == 2:  # Don't show boxes or ids for ignore regions\n",
    "                    x, y, w, h = map(int, rletools.toBbox(obj.mask))\n",
    "                    fig = plt.figure()\n",
    "                    ax = fig.subplots()\n",
    "                    ax.set_axis_off()\n",
    "                    ax.imshow(img[y:y+h,x:x+w])\n",
    "                    fig.savefig(os.path.join(output_folder, 'sequences', seq_id, str(obj.track_id), \"%06d\" % t + \".jpg\"))\n",
    "                # if obj.class_id == 1 or obj.class_id == 2:  # Don't show boxes or ids for ignore regions\n",
    "                #     x, y, w, h = rletools.toBbox(obj.mask)\n",
    "                #     if draw_boxes:\n",
    "                #         import matplotlib.patches as patches\n",
    "                #         rect = patches.Rectangle((x, y), w, h, linewidth=1,\n",
    "                #                                  edgecolor=color, facecolor='none', alpha=1.0)\n",
    "                #         ax.add_patch(rect)\n",
    "                #     category_name += \":\" + str(obj.track_id)\n",
    "                #     ax.annotate(category_name, (x + 0.5 * w, y + 0.5 * h), color=color, weight='bold',\n",
    "                #               fontsize=7, ha='center', va='center', alpha=1.0)\n",
    "                # binary_mask = rletools.decode(obj.mask)\n",
    "                # apply_mask(img, binary_mask, color)\n",
    "                plt.close(fig)\n",
    "\n",
    "        # ax.imshow(img)\n",
    "        # fig.savefig(output_folder + \"/\" + seq_id + \"/%06d\" % t + \".jpg\")\n",
    "        # plt.close(fig)\n",
    "    # if create_video:\n",
    "    #     os.chdir(output_folder + \"/\" + seq_id)\n",
    "    #     call([\"ffmpeg\", \"-framerate\", \"10\", \"-y\", \"-i\", \"%06d.jpg\", \"-c:v\", \"libx264\", \"-profile:v\", \"high\", \"-crf\", \"20\",\n",
    "    #           \"-pix_fmt\", \"yuv420p\", \"-vf\", \"pad=\\'width=ceil(iw/2)*2:height=ceil(ih/2)*2\\'\", \"output.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022cbb3-255f-4f1d-8bae-50cb2355ce97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_folder = './kitti-mots/instances_txt'\n",
    "img_folder = './kitti-mots/data_tracking_image_2/training/image_02/'\n",
    "output_folder = './outputs'\n",
    "seqmap_filename = './kitti-mots/sequence_map.txt'\n",
    "\n",
    "seqmap, max_frames = load_seqmap(seqmap_filename)\n",
    "process_sequence_part = partial(process_sequence_2, max_frames=max_frames,\n",
    "                              tracks_folder=tracks_folder, img_folder=img_folder, output_folder=output_folder)\n",
    "\n",
    "with Pool(70) as pool:\n",
    "    pool.map(process_sequence_part, seqmap)\n",
    "    #for seq in seqmap:\n",
    "    #  process_sequence_part(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7cb330-dc77-42e3-bf87-2fac1e812527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34863dfc-18eb-4d30-a180-97df2308142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4ee566-cacd-4b31-b31a-80bebc94be50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af63397-e503-459f-8f4d-def6801d5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    'ViT-B-32',\n",
    "    pretrained='laion2b_s34b_b79k',\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419a5611-2af5-48d0-a89f-7f26e424c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence_3(\n",
    "    seq_id, tracks_folder, img_folder, output_folder,\n",
    "    max_frames, draw_boxes=False, create_video=True,\n",
    "):\n",
    "    print(\"Processing sequence\", seq_id)\n",
    "    os.makedirs(output_folder + \"/\" + seq_id, exist_ok=True)\n",
    "    tracks = load_sequences(tracks_folder, [seq_id])[seq_id]\n",
    "    max_frames_seq = max_frames[seq_id]\n",
    "\n",
    "    assert os.path.exists(os.path.join(output_folder, 'sequences', seq_id))\n",
    "    if not os.path.exists(os.path.join(output_folder, 'features', seq_id)):\n",
    "        os.makedirs(os.path.join(output_folder, 'features', seq_id))\n",
    "    for t in tqdm(range(max_frames_seq + 1)):\n",
    "        # print(\"Processing frame\", t)\n",
    "\n",
    "        if t in tracks:\n",
    "            for obj in tracks[t]:\n",
    "                assert os.path.exists(os.path.join(output_folder, 'sequences', seq_id, str(obj.track_id)))\n",
    "                if not os.path.exists(os.path.join(output_folder, 'features', seq_id, str(obj.track_id))):\n",
    "                    os.makedirs(os.path.join(output_folder, 'features', seq_id, str(obj.track_id)))\n",
    "                if obj.class_id == 1 or obj.class_id == 2:  # Don't show boxes or ids for ignore regions\n",
    "                    img = Image.open(os.path.join(output_folder, 'sequences', seq_id, str(obj.track_id), \"%06d\" % t + \".jpg\"))\n",
    "                    image = preprocess(img).unsqueeze(0)\n",
    "                    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                        image_features = model.encode_image(image.to(device))\n",
    "                        torch.save(\n",
    "                            image_features,\n",
    "                            os.path.join(\n",
    "                                output_folder,\n",
    "                                'features',\n",
    "                                seq_id,\n",
    "                                str(obj.track_id),\n",
    "                                \"%06d\" % t + \".pt\",\n",
    "                            )\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30329c0e-c99c-4519-8e69-341d9eebcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seqmap...\n",
      "GPU: True\n",
      "Processing sequence 0000\n",
      "Loading sequence 0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:05<00:00, 30.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 0020\n",
      "Loading sequence 0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [01:10<00:00, 11.95it/s]\n"
     ]
    }
   ],
   "source": [
    "tracks_folder = './kitti-mots/instances_txt'\n",
    "img_folder = './kitti-mots/data_tracking_image_2/training/image_02/'\n",
    "output_folder = './outputs'\n",
    "seqmap_filename = './kitti-mots/sequence_map.txt'\n",
    "\n",
    "seqmap, max_frames = load_seqmap(seqmap_filename)\n",
    "process_sequence_part = partial(process_sequence_3, max_frames=max_frames,\n",
    "                              tracks_folder=tracks_folder, img_folder=img_folder, output_folder=output_folder)\n",
    "\n",
    "print('GPU:', torch.cuda.is_available())\n",
    "\n",
    "for seq in seqmap:\n",
    "    process_sequence_part(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fbdfff-8e80-4c69-b3db-9a7acfd18c98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e026a8b-19d9-4e08-a496-e9bf45149915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=os.environ[\"PINECONE_API\"], environment=\"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d82b4-e2f1-4002-bffe-fe8058b450aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pinecone.manage.create_index(name: str, dimension: int, timeout: int = None, index_type: str = 'approximated', metric: str = 'cosine', replicas: int = 1, shards: int = 1, pods: int = 1, pod_type: str = 'p1', index_config: dict = None, metadata_config: dict = None, source_collection: str = '')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.create_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbefbab-d668-4b1a-9e46-0c4b2b847064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pinecone.create_index(\"tracks\", dimension=512, metric=\"euclidean\")\n",
    "# pinecone.describe_index(\"tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76b811d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='tracks', metric='euclidean', replicas=1, dimension=512.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.describe_index('tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a479f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index('tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f622b796-632b-42cd-b374-33110aae5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush(vectors, force=False):\n",
    "    if len(vectors) > 20 or (force and len(vectors) > 0):\n",
    "        index.upsert(\n",
    "            vectors=[\n",
    "                {\"id\": f\"{t}-{tid}\", \"values\": vector}\n",
    "                for tid, t, vector in vectors\n",
    "            ],\n",
    "            namespace=\"images\"\n",
    "        )\n",
    "        return []\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def process_sequence_4(\n",
    "    seq_id, tracks_folder, img_folder, output_folder,\n",
    "    max_frames, draw_boxes=False, create_video=True,\n",
    "):\n",
    "    print(\"Processing sequence\", seq_id)\n",
    "    os.makedirs(output_folder + \"/\" + seq_id, exist_ok=True)\n",
    "    tracks = load_sequences(tracks_folder, [seq_id])[seq_id]\n",
    "    max_frames_seq = max_frames[seq_id]\n",
    "\n",
    "    vectors = []\n",
    "    assert os.path.exists(os.path.join(output_folder, 'features', seq_id))\n",
    "    for t in tqdm(range(max_frames_seq + 1)):\n",
    "        # print(\"Processing frame\", t)\n",
    "\n",
    "        if t in tracks:\n",
    "            for obj in tracks[t]:\n",
    "                assert os.path.exists(os.path.join(output_folder, 'features', seq_id, str(obj.track_id)))\n",
    "                if obj.class_id == 1 or obj.class_id == 2:  # Don't show boxes or ids for ignore regions\n",
    "                    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                        features = torch.load(\n",
    "                            os.path.join(\n",
    "                                output_folder,\n",
    "                                'features',\n",
    "                                seq_id,\n",
    "                                str(obj.track_id),\n",
    "                                \"%06d\" % t + \".pt\",\n",
    "                            )\n",
    "                        )\n",
    "                        vectors.append((obj.track_id, t, features.reshape((-1,)).detach().cpu().tolist()))\n",
    "                        vectors = flush(vectors)\n",
    "    \n",
    "    flush(vectors, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae4c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seqmap...\n",
      "GPU: True\n",
      "Processing sequence 0000\n",
      "Loading sequence 0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5268f0915354a9aaad8d349237d60ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 0020\n",
      "Loading sequence 0020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f991d23803124270b291b529414accf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tracks_folder = '/code/kitti-mots/instances_txt'\n",
    "img_folder = '/code/kitti-mots/data_tracking_image_2/training/image_02/'\n",
    "output_folder = '/code/outputs'\n",
    "seqmap_filename = '/code/kitti-mots/sequence_map.txt'\n",
    "\n",
    "seqmap, max_frames = load_seqmap(seqmap_filename)\n",
    "process_sequence_part = partial(process_sequence_4, max_frames=max_frames,\n",
    "                              tracks_folder=tracks_folder, img_folder=img_folder, output_folder=output_folder)\n",
    "\n",
    "print('GPU:', torch.cuda.is_available())\n",
    "\n",
    "for seq in seqmap:\n",
    "    process_sequence_part(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafcb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torch.load('/code/outputs/features/0020/1012/000184.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1bc435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_vec = vec.reshape((-1,)).cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e770e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '184-1012', 'score': 0.0, 'values': []},\n",
       "             {'id': '183-1012', 'score': 8.79399109, 'values': []},\n",
       "             {'id': '182-1012', 'score': 10.2688141, 'values': []},\n",
       "             {'id': '187-1012', 'score': 11.3680267, 'values': []},\n",
       "             {'id': '186-1012', 'score': 11.8865814, 'values': []},\n",
       "             {'id': '185-1012', 'score': 14.087265, 'values': []},\n",
       "             {'id': '188-1012', 'score': 15.1789856, 'values': []},\n",
       "             {'id': '181-1012', 'score': 15.5930939, 'values': []},\n",
       "             {'id': '548-1088', 'score': 16.9915619, 'values': []},\n",
       "             {'id': '193-1012', 'score': 17.2358093, 'values': []},\n",
       "             {'id': '322-1012', 'score': 18.2238, 'values': []},\n",
       "             {'id': '600-1012', 'score': 18.4443054, 'values': []},\n",
       "             {'id': '595-1012', 'score': 18.5437927, 'values': []},\n",
       "             {'id': '190-1012', 'score': 19.0632782, 'values': []},\n",
       "             {'id': '596-1012', 'score': 19.9517822, 'values': []},\n",
       "             {'id': '607-1012', 'score': 20.1295166, 'values': []},\n",
       "             {'id': '591-1012', 'score': 20.5048676, 'values': []},\n",
       "             {'id': '109-1009', 'score': 20.5597687, 'values': []},\n",
       "             {'id': '533-1012', 'score': 20.6296844, 'values': []},\n",
       "             {'id': '194-1012', 'score': 20.7514343, 'values': []}],\n",
       " 'namespace': 'images'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\n",
    "  namespace=\"images\",\n",
    "  vector=_vec,\n",
    "  top_k=20,\n",
    "  include_value=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a62e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
